{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "20dXfRAA5Wl0"
      },
      "outputs": [],
      "source": [
        "# Download audio  transcripts from 10 youtube videos.\n",
        "#Use the method created above to generate a ‘vector store’ based on the transcripts of these videos.\n",
        "#Create a vector store and embeddings based on this data.\n",
        "#Document loading\n",
        "#Document splitting\n",
        "#And Vector store section\n",
        "\n",
        "def parse_transcript_file(file_path, interval_seconds):\n",
        "  result = []\n",
        "  with open(file_path, 'I') as file:\n",
        "    lines = file.readlines()\n",
        "  start_time = 0\n",
        "  end_time = interval_seconds\n",
        "  current_text = \"\"\n",
        "\n",
        "  for line in lines:\n",
        "        time_str, text = line.split(',', 1)\n",
        "        # The line below calculates the total time in seconds from a time string in the format \"mm:ss\"\n",
        "        # time_str is a string representing the time in the format \"mm:ss\"\n",
        "        # The strip() function removes any leading/trailing whitespace\n",
        "        # The split(':') function splits the string into a list of two elements, representing minutes and seconds\n",
        "        # The zip function pairs the elements of the list \"[60, 1]\" with the elements of the time string's list obtained in the previous step\n",
        "\n",
        "        time_in_seconds = sum(x * int(t) for x, t in zip([60, 1], time_str.strip().split(':')))\n",
        "        if time_in_seconds < end_time:\n",
        "            current_text += text.strip()\n",
        "        else:\n",
        "            result.append((f\"{start_time // 60:02}:{start_time % 60:02}\",\n",
        "                           f\"{end_time // 60:02}:{end_time % 60:02}\", current_text))\n",
        "            current_text = text.strip()\n",
        "            start_time = end_time\n",
        "            end_time += interval_seconds\n",
        "\n",
        "  if current_text:\n",
        "        result.append((f\"{start_time // 60:02}:{start_time % 60:02}\",\n",
        "                       f\"{end_time // 60:02}:{end_time % 60:02}\", current_text))\n",
        "        return result;\n",
        "\n",
        "file_path = \"video1.txt\"\n",
        "interval_seconds = 30\n",
        "result = parse_transcript_file(file_path, interval_seconds)\n",
        "print(result)\n",
        "\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "def load_transcript(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        return file.readlines()\n",
        "\n",
        "def create_vector_store(transcripts, interval_seconds):\n",
        "    vector_store = {}\n",
        "    embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
        "\n",
        "    for transcript in transcripts:\n",
        "        parsed_intervals = parse_transcript_file(transcript, interval_seconds)\n",
        "        for start_time, end_time, text in parsed_intervals:\n",
        "            # Concatenate start time and end time to create a unique key for each interval\n",
        "            key = f\"{start_time}_{end_time}\"\n",
        "            embedding = embed([text])[0].numpy()\n",
        "            vector_store[key] = embedding\n",
        "\n",
        "    return vector_store\n",
        "\n",
        "#usage:\n",
        "transcript_files = [\"video1.txt\"]\n",
        "interval_seconds = 30\n",
        "\n",
        "transcripts = [load_transcript(file) for file in transcript_files]\n",
        "vector_store = create_vector_store(transcripts, interval_seconds)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "mVDpp327PQc4"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BDu57WkcME45"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}